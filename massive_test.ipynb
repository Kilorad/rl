{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './env')\n",
    "sys.path.insert(1, './agents')\n",
    "\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import strategy_imitation, sarsa, ddqn, random_agent, a2c, model_based\n",
    "import aa_gun\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#массовый тест моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____ random 0 2020-02-14 16:55:30.136397\n",
      "episode: 0   score: 0.375 0.375   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 1   score: 1.25 0.8125   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 2   score: 1.4375 1.0208333333333333   memory length: 0   epsilon: 1\n",
      "episode: 3   score: 1.0625 1.03125   memory length: 0   epsilon: 1\n",
      "episode: 4   score: 1.0 1.025   memory length: 0   epsilon: 1\n",
      "episode: 5   score: 0.25 0.8958333333333334   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 6   score: 2.4375 1.1160714285714286   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 7   score: 1.5625 1.171875   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 8   score: 2.75 1.3472222222222223   memory length: 0   epsilon: 1\n",
      "episode: 9   score: 1.4375 1.35625   memory length: 0   epsilon: 1\n",
      "episode: 10   score: 0.25 1.2556818181818181   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 11   score: 2.1875 1.3333333333333333   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 12   score: 1.9375 1.3798076923076923   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 13   score: 1.5625 1.3928571428571428   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 14   score: 1.75 1.4166666666666667   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 15   score: 2.3125 1.47265625   memory length: 0   epsilon: 1\n",
      "episode: 16   score: 0.25 1.400735294117647   memory length: 0   epsilon: 1\n",
      "episode: 17   score: 0.9375 1.375   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 18   score: 2.8125 1.450657894736842   memory length: 0   epsilon: 1\n",
      "episode: 19   score: 0.625 1.409375   memory length: 0   epsilon: 1\n",
      "episode: 20   score: 0.125 1.3482142857142858   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "episode: 21   score: 3.6875 1.4545454545454546   memory length: 0   epsilon: 1\n",
      "episode: 22   score: 0 1.391304347826087   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 23   score: 2.3125 1.4296875   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "episode: 24   score: 4.25 1.5425   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 25   score: 1.25 1.53125   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 26   score: 2.3125 1.5601851851851851   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 27   score: 2.0625 1.578125   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 28   score: 1.9375 1.5905172413793103   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 29   score: 2.25 1.6125   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 30   score: 2.375 1.6370967741935485   memory length: 0   epsilon: 1\n",
      "episode: 31   score: 1.5 1.6328125   memory length: 0   epsilon: 1\n",
      "episode: 32   score: 0.9375 1.6117424242424243   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 33   score: 2.125 1.6268382352941178   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 34   score: 1.375 1.6196428571428572   memory length: 0   epsilon: 1\n",
      "episode: 35   score: 1.375 1.6128472222222223   memory length: 0   epsilon: 1\n",
      "episode: 36   score: 1.1875 1.6013513513513513   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 37   score: 3.375 1.6480263157894737   memory length: 0   epsilon: 1\n",
      "episode: 38   score: 0.0625 1.607371794871795   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 39   score: 1.8125 1.6125   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 40   score: 1 1.5975609756097562   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 41   score: 1.3125 1.5907738095238095   memory length: 0   epsilon: 1\n",
      "episode: 42   score: 1.375 1.5857558139534884   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 43   score: 1.8125 1.5909090909090908   memory length: 0   epsilon: 1\n",
      "episode: 44   score: 0.9375 1.5763888888888888   memory length: 0   epsilon: 1\n",
      "episode: 45   score: 0.25 1.547554347826087   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 46   score: 1.3125 1.5425531914893618   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 47   score: 2.5 1.5625   memory length: 0   epsilon: 1\n",
      "episode: 48   score: 0.625 1.5433673469387754   memory length: 0   epsilon: 1\n",
      "episode: 49   score: 0.4375 1.52125   memory length: 0   epsilon: 1\n",
      "episode: 50   score: 1.625 1.5232843137254901   memory length: 0   epsilon: 1\n",
      "episode: 51   score: 0.5 1.5036057692307692   memory length: 0   epsilon: 1\n",
      "episode: 52   score: 1.125 1.4964622641509433   memory length: 0   epsilon: 1\n",
      "episode: 53   score: 0.5 1.4780092592592593   memory length: 0   epsilon: 1\n",
      "episode: 54   score: 0.9375 1.4681818181818183   memory length: 0   epsilon: 1\n",
      "episode: 55   score: 1.9375 1.4765625   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 56   score: 2.25 1.4901315789473684   memory length: 0   epsilon: 1\n",
      "episode: 57   score: 1.0 1.4816810344827587   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 58   score: 2.1875 1.49364406779661   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 59   score: 3.0 1.51875   memory length: 0   epsilon: 1\n",
      "episode: 60   score: 1.0625 1.5112704918032787   memory length: 0   epsilon: 1\n",
      "episode: 61   score: 0.8125 1.5   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 62   score: 1.625 1.501984126984127   memory length: 0   epsilon: 1\n",
      "episode: 63   score: 0.875 1.4921875   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 64   score: 1.5 1.4923076923076923   memory length: 0   epsilon: 1\n",
      "episode: 65   score: 1.3125 1.4895833333333333   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 66   score: 3.1875 1.5149253731343284   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 67   score: 2.4375 1.5284926470588236   memory length: 0   epsilon: 1\n",
      "episode: 68   score: 0.0625 1.5072463768115942   memory length: 0   epsilon: 1\n",
      "episode: 69   score: 0.75 1.4964285714285714   memory length: 0   epsilon: 1\n",
      "episode: 70   score: 1.375 1.494718309859155   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 71   score: 2.25 1.5052083333333333   memory length: 0   epsilon: 1\n",
      "episode: 72   score: 0.125 1.4863013698630136   memory length: 0   epsilon: 1\n",
      "episode: 73   score: 0.8125 1.477195945945946   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 74   score: 2.0625 1.485   memory length: 0   epsilon: 1\n",
      "episode: 75   score: 0.5625 1.472861842105263   memory length: 0   epsilon: 1\n",
      "episode: 76   score: 0.8125 1.4642857142857142   memory length: 0   epsilon: 1\n",
      "episode: 77   score: 0.375 1.4503205128205128   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 78   score: 2.625 1.4651898734177216   memory length: 0   epsilon: 1\n",
      "episode: 79   score: 1.0625 1.46015625   memory length: 0   epsilon: 1\n",
      "episode: 80   score: 0.6875 1.4506172839506173   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 81   score: 1.1875 1.447408536585366   memory length: 0   epsilon: 1\n",
      "episode: 82   score: 0.6875 1.4382530120481927   memory length: 0   epsilon: 1\n",
      "episode: 83   score: 0.25 1.4241071428571428   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 84   score: 1.75 1.4279411764705883   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 85   score: 2.0625 1.4353197674418605   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 86   score: 1.5625 1.4367816091954022   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 87   score: 1.1875 1.4339488636363635   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 88   score: 3.5 1.4571629213483146   memory length: 0   epsilon: 1\n",
      "episode: 89   score: 1.375 1.45625   memory length: 0   epsilon: 1\n",
      "episode: 90   score: 0.3125 1.4436813186813187   memory length: 0   epsilon: 1\n",
      "episode: 91   score: 0.1875 1.4300271739130435   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 92   score: 2.3125 1.439516129032258   memory length: 0   epsilon: 1\n",
      "episode: 93   score: 0.75 1.4321808510638299   memory length: 0   epsilon: 1\n",
      "episode: 94   score: 1.0 1.4276315789473684   memory length: 0   epsilon: 1\n",
      "episode: 95   score: 2.0625 1.4342447916666667   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 96   score: 2.9375 1.449742268041237   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 97   score: 1.6875 1.4521683673469388   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 98   score: 1.625 1.4539141414141414   memory length: 0   epsilon: 1\n",
      "episode: 99   score: 0.625 1.445625   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 100   score: 1.625 1.44740099009901   memory length: 0   epsilon: 1\n",
      "episode: 101   score: 0.1875 1.4350490196078431   memory length: 0   epsilon: 1\n",
      "episode: 102   score: 0.375 1.424757281553398   memory length: 0   epsilon: 1\n",
      "episode: 103   score: 0.1875 1.4128605769230769   memory length: 0   epsilon: 1\n",
      "episode: 104   score: 0.8125 1.4071428571428573   memory length: 0   epsilon: 1\n",
      "episode: 105   score: 0.9375 1.4027122641509433   memory length: 0   epsilon: 1\n",
      "episode: 106   score: 0 1.3896028037383177   memory length: 0   epsilon: 1\n",
      "episode: 107   score: 0.25 1.3790509259259258   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 108   score: 2.75 1.3916284403669725   memory length: 0   epsilon: 1\n",
      "hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 109   score: 1.0625 1.3886363636363637   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 110   score: 2.25 1.3963963963963963   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 111   score: 1.875 1.4006696428571428   memory length: 0   epsilon: 1\n",
      "episode: 112   score: 1.625 1.4026548672566372   memory length: 0   epsilon: 1\n",
      "episode: 113   score: 3.8125 1.4237938596491229   memory length: 0   epsilon: 1\n",
      "hit\n",
      "hit\n",
      "episode: 114   score: 3.0625 1.4380434782608695   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 115   score: 1.375 1.4375   memory length: 0   epsilon: 1\n",
      "episode: 116   score: 0.9375 1.4332264957264957   memory length: 0   epsilon: 1\n",
      "episode: 117   score: 0.75 1.427436440677966   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 118   score: 1.5 1.428046218487395   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 119   score: 1.9375 1.4322916666666667   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 120   score: 1.9375 1.4364669421487604   memory length: 0   epsilon: 1\n",
      "episode: 121   score: 0.5625 1.4293032786885247   memory length: 0   epsilon: 1\n",
      "hit\n",
      "episode: 122   score: 1.8125 1.4324186991869918   memory length: 0   epsilon: 1\n",
      "hit\n"
     ]
    }
   ],
   "source": [
    "#Проверь на зенитке, на cartpole и на mountain car\n",
    "\n",
    "score_dict_full={'random':[],'ddqn':[],'a2c':[],'sarsa':[],'mb':[]}\n",
    "border_med = 100\n",
    "EPISODES=140\n",
    "score_dict_med={'random':[],'ddqn':[],'a2c':[],'sarsa':[],'mb':[]}#c border_med по... такты. Надо, чтобы проверить быстроту обучения\n",
    "\n",
    "agent_list=[random_agent.randomAgent,a2c.A2CAgent,ddqn.DoubleDQNAgent,sarsa.SarsaAgent,model_based.ModelBasedAgent]\n",
    "for ag_num in [0,3,4]:\n",
    "    if ag_num==0:\n",
    "        name='random'\n",
    "    if ag_num==1:\n",
    "        name='a2c'\n",
    "    if ag_num==2:\n",
    "        name='ddqn' \n",
    "    if ag_num==3:\n",
    "        name='sarsa'\n",
    "    if ag_num==4:\n",
    "        name='mb'\n",
    "    \n",
    "    for estimation in range(2):\n",
    "        print('_____',name,estimation,pd.Timestamp.now())\n",
    "        #здесь весь код от инициализации модели до выдачи scores. Но без рендера.\n",
    "        # In case of CartPole-v1, maximum length of episode is 500\n",
    "        \n",
    "        env = aa_gun.AA_gun_simple0_env()\n",
    "        #env = gym.make('Seaquest-ramNoFrameskip-v0')\n",
    "        #env=CartPoleEnv9()\n",
    "        # get size of state and action from environment\n",
    "        state_size = env.observation_space.shape[0]\n",
    "        action_size = env.action_space.n\n",
    "\n",
    "        #agent = DoubleDQNAgent(state_size, action_size)\n",
    "        agent = agent_list[ag_num](state_size, action_size)\n",
    "        agent.train_start=1000\n",
    "        #agent.train_start=7000\n",
    "        agent.epsilon_decay=0.9999\n",
    "        agent.render=False\n",
    "\n",
    "        scores, episodes = [], []\n",
    "        reward_lst = []\n",
    "        s_list=[]\n",
    "        a_list=[]\n",
    "\n",
    "        for e in range(EPISODES):\n",
    "            done = False\n",
    "            score = 0\n",
    "            state = env.reset()\n",
    "            state = np.reshape(state, [1, state_size])\n",
    "\n",
    "            while not done:\n",
    "                #if (e in range(2,7)) or (e in range(20,25)) or (e in range(100,103)) or (e in range(200,202)) or (e in range(300,306)) or (e in range(400,406)) or (e in range(500,506)) or (e in range(600,604)):\n",
    "                #    if agent.render:\n",
    "                #        env.render()\n",
    "\n",
    "                # get action for the current state and go one step in environment\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, info = env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, state_size])\n",
    "                # if an action make the episode end, then gives penalty of -100\n",
    "\n",
    "                \n",
    "                # save the sample <s, a, r, s'> to the replay memory\n",
    "                agent.append_sample(state, action, reward, next_state, done)\n",
    "                #if next_state[0,11]!=reward:\n",
    "                #    print('state[13]!=reward',state[0,11],reward)\n",
    "                #\n",
    "                s_list.append(state)\n",
    "                a_list.append(action)\n",
    "                reward_lst.append(reward)\n",
    "                #\n",
    "\n",
    "                # every time step do the training\n",
    "                agent.train_model()\n",
    "                score += reward\n",
    "                state = next_state\n",
    "\n",
    "                if done:\n",
    "                    # every episode update the target model to be same with model\n",
    "                    agent.update_target_model()\n",
    "\n",
    "                    # every episode, plot the play time\n",
    "                    scores.append(score)\n",
    "                    episodes.append(e)\n",
    "                    pylab.plot(episodes, scores, 'b')\n",
    "                    #pylab.savefig(\"./save_graph/aa_gun_dqn.png\")\n",
    "                    try:\n",
    "                        print(\"episode:\", e, \"  score:\", score,np.mean(scores), \"  memory length:\",\n",
    "                              len(agent.s), \"  epsilon:\", agent.epsilon)\n",
    "                    except Exception:\n",
    "                        print(\"episode:\", e, \"  score:\", score,np.mean(scores), \"  memory length:\",\n",
    "                              len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "\n",
    "\n",
    "            # save the model\n",
    "            #if e % 50 == 0:\n",
    "            #    agent.model.save_weights(\"./save_model/aa_gun_dqn.h5\")\n",
    "\n",
    "\n",
    "\n",
    "        #и первые 3000 тактов - это рандом\n",
    "        #Ходов так 50\n",
    "        score_dict_full[name].append(np.mean(scores))\n",
    "        score_dict_med[name].append(np.mean(scores[border_med:]))\n",
    "        import pickle\n",
    "        f=open('score_dict.pkl','wb')\n",
    "        pickle.dump([score_dict_full,score_dict_med],f)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
