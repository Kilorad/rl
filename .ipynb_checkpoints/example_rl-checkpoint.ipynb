{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './env')\n",
    "sys.path.insert(1, './agents')\n",
    "\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import aa_gun\n",
    "import strategy_imitation, sarsa\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPISODES = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:72: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4048: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 160)               2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 29,281\n",
      "Trainable params: 28,641\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:782: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 160)               3200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 30,401\n",
      "Trainable params: 29,761\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 160)               2240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 160)               25760     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 1127      \n",
      "=================================================================\n",
      "Total params: 30,407\n",
      "Trainable params: 29,767\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/s.dovgan/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3218: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "episode: 0   score: 0.0625   memory length: 250   epsilon: 0.7787033741169904\n",
      "episode: 1   score: 0.5   memory length: 500   epsilon: 0.6063789448611848\n",
      "hit\n",
      "episode: 2   score: 1.0625   memory length: 750   epsilon: 0.47218933035690447\n",
      "hit\n",
      "episode: 3   score: 1.9375   memory length: 1000   epsilon: 0.3676954247709635\n",
      "hit\n",
      "episode: 4   score: 1.5625   memory length: 1250   epsilon: 0.28632566791652947\n",
      "episode: 5   score: 0.875   memory length: 1500   epsilon: 0.22296276370290227\n",
      "hit\n",
      "episode: 6   score: 1.5   memory length: 1750   epsilon: 0.17362185639789907\n",
      "hit\n",
      "episode: 7   score: 1.6875   memory length: 2000   epsilon: 0.1351999253974994\n",
      "episode: 8   score: 1.75   memory length: 2250   epsilon: 0.10528063808739813\n",
      "episode: 9   score: 0.8125   memory length: 2500   epsilon: 0.08198238810784661\n",
      "episode: 10   score: 1.3125   memory length: 2750   epsilon: 0.06383996223774882\n",
      "WARNING:tensorflow:From /home/s.dovgan/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.7132\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6860\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6704\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6597\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6426\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6410\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6191\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6164\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.5963\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.5830\n",
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6160\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.6122\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.5885\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 0s 5us/step - loss: 2.5688\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 0s 5us/step - loss: 2.5542\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.5442\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.5381\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.5210\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.4969\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 0s 6us/step - loss: 2.4855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_r:min,max,mean,perc 60 -0.6450052326538728 1.4017235004478468 0.057209874975699314 0.17371245154170767 idx_good_decisions_count 1167\n",
      "Epoch 1/12\n",
      "1167/1167 [==============================] - 0s 10us/step - loss: 3.8630 - acc: 0.2262\n",
      "Epoch 2/12\n",
      "1167/1167 [==============================] - 0s 10us/step - loss: 3.8324 - acc: 0.2322\n",
      "Epoch 3/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.7502 - acc: 0.2459\n",
      "Epoch 4/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.6419 - acc: 0.2605\n",
      "Epoch 5/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.5559 - acc: 0.2776\n",
      "Epoch 6/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.4720 - acc: 0.2845\n",
      "Epoch 7/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.4431 - acc: 0.2999\n",
      "Epoch 8/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.3967 - acc: 0.3051\n",
      "Epoch 9/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.3116 - acc: 0.3393\n",
      "Epoch 10/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.3079 - acc: 0.3162\n",
      "Epoch 11/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.3004 - acc: 0.3350\n",
      "Epoch 12/12\n",
      "1167/1167 [==============================] - 0s 9us/step - loss: 3.2229 - acc: 0.3462\n",
      "episode: 11   score: 0.375   memory length: 3000   epsilon: 0.04971239399803625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-59dbd9f5e49c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# every time step do the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/QL_test/rl/agents/strategy_imitation.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, epochs, sub_batch_size, verbose)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mdelta_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr_sr_predicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         self.model_sar.fit(np.hstack((s,a)), delta_r, batch_size=self.batch_size,\n\u001b[0;32m--> 219\u001b[0;31m                        epochs=epochs, verbose=verbose)\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;31m#А здесь сделать аугментацию!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m#a = np.array(np.argmax(agent.a,axis=1),ndmin=2).T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72563d66d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In case of CartPole-v1, maximum length of episode is 500\n",
    "env = aa_gun.AA_gun_simple0_env()\n",
    "#env=CartPoleEnv9()\n",
    "# get size of state and action from environment\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "#agent = DoubleDQNAgent(state_size, action_size)\n",
    "agent = sarsa.SarsaAgent(state_size, action_size)\n",
    "#agent = strategy_imitation.ImitAgent(state_size, action_size)\n",
    "agent.render=False\n",
    "\n",
    "scores, episodes = [], []\n",
    "reward_lst = []\n",
    "s_list=[]\n",
    "a_list=[]\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    while not done:\n",
    "        if (e in range(2,7)) or (e in range(20,25)) or (e in range(100,103)) or (e in range(200,202)) or (e in range(300,306)) or (e in range(400,406)) or (e in range(500,506)) or (e in range(600,604)):\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "\n",
    "        # get action for the current state and go one step in environment\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        # if an action make the episode end, then gives penalty of -100\n",
    "        \n",
    "\n",
    "        # save the sample <s, a, r, s'> to the replay memory\n",
    "        agent.append_sample(state, action, reward, next_state, done)\n",
    "        #if next_state[0,11]!=reward:\n",
    "        #    print('state[13]!=reward',state[0,11],reward)\n",
    "        #\n",
    "        s_list.append(state)\n",
    "        a_list.append(action)\n",
    "        reward_lst.append(reward)\n",
    "        #\n",
    "        \n",
    "        # every time step do the training\n",
    "        agent.train_model()\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            # every episode update the target model to be same with model\n",
    "            agent.update_target_model()\n",
    "\n",
    "            # every episode, plot the play time\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, scores, 'b')\n",
    "            #pylab.savefig(\"./save_graph/aa_gun_dqn.png\")\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 490\n",
    "            # stop training\n",
    "\n",
    "    # save the model\n",
    "    #if e % 50 == 0:\n",
    "    #    agent.model.save_weights(\"./save_model/aa_gun_dqn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sar_table(s,a,r):\n",
    "    #print(np.array(a,ndmin=2).T.shape)\n",
    "    #print(np.array(r,ndmin=2).T.shape)\n",
    "    #print(np.array(s,ndmin=2)[:,0,:].shape)\n",
    "    return np.hstack( (np.array(s,ndmin=2)[:,0,:],np.array(a,ndmin=2).T,np.array(r,ndmin=2).T) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(np.mean(reward_lst))\n",
    "plt.plot(reward_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agent.r_disco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(reward_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтобы анализировать разрешимость задачи\n",
    "def replicate_reward(sar,border=0,wanted_part=0.5):\n",
    "    part = np.mean(sar[:,-1:]>border)\n",
    "    if part==0:\n",
    "        print('ERROR')\n",
    "        return(sar)\n",
    "    else:\n",
    "        while part<wanted_part:\n",
    "            sar=np.vstack((sar,sar[np.where(sar[:,-1:]>border)[0],:]))\n",
    "            part = np.mean(sar[:,-1:]>border)\n",
    "        print(part)\n",
    "        return(sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar=make_sar_table(s_list,a_list,reward_lst)\n",
    "sar=replicate_reward(sar)\n",
    "X=sar[1:,:]\n",
    "Y=sar[:-1,:]\n",
    "Y=sar[:-1,-1:]\n",
    "Y=sar[1:,-1:]\n",
    "sar_width=X.shape[1]\n",
    "nn = Sequential()\n",
    "nn.add(Dense(200, input_dim=sar_width, activation='relu',\n",
    "                kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(200, activation='relu',\n",
    "                kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dense(200, activation='relu',\n",
    "                kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(BatchNormalization())\n",
    "#nn.add(Dense(sar_width, activation='linear',\n",
    "#                kernel_initializer='he_uniform'))\n",
    "nn.add(Dense(1, activation='linear',\n",
    "                kernel_initializer='he_uniform'))\n",
    "\n",
    "nn.summary()\n",
    "nn.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "l=X.shape[0]\n",
    "X_train=X[:int(l/2),:]\n",
    "Y_train=Y[:int(l/2),:]\n",
    "X_test=X[int(l/2):,:]\n",
    "Y_test=Y[int(l/2):,:]\n",
    "nn.fit(X_train, Y_train, batch_size=1200,epochs=30000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=np.array(nn.predict(X_test),ndmin=2)\n",
    "mse = np.mean((Y_pred-Y_test)**2)\n",
    "print(mse)\n",
    "rmae=np.mean(np.abs(Y_pred-Y_test))/np.mean(np.abs(Y_test))\n",
    "print(rmae)\n",
    "rmae_diversed=np.mean(np.abs(Y_pred-Y_test),axis=0)/np.mean(np.abs(Y_test),axis=0)\n",
    "print(rmae_diversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnumn_num=-1\n",
    "plt.plot(Y_pred[:3000,colnumn_num])\n",
    "plt.plot(Y_test[:3000,colnumn_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train (переобучение?)\n",
    "Y_pred=np.array(nn.predict(X_train),ndmin=2)\n",
    "mse = np.mean((Y_pred-Y_train)**2)\n",
    "print(mse)\n",
    "rmae=np.mean(np.abs(Y_pred-Y_train))/np.mean(np.abs(Y_train))\n",
    "print(rmae)\n",
    "rmae_diversed=np.mean(np.abs(Y_pred-Y_train),axis=0)/np.mean(np.abs(Y_train),axis=0)\n",
    "print(rmae_diversed)\n",
    "\n",
    "colnumn_num=-1\n",
    "plt.plot(Y_pred[:1300,colnumn_num])\n",
    "plt.plot(Y_train[:1300,colnumn_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgbparams = {\n",
    "    'booster':'gbtree',\n",
    "    'metric':'mse',\n",
    "    'objective':'reg:squarederror',\n",
    "    'verbosity':0,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 90,\n",
    "    'eta': 0.3,\n",
    "    'nthreads': 2,\n",
    "    'seed':0\n",
    "}\n",
    "nn=xgb.XGBRegressor(**xgbparams)\n",
    "nn.fit(X_train[:int(l/4),:], Y_train[:int(l/4),:],\n",
    "           eval_set=[(X_train[int(l/4):,:], Y_train[int(l/4):,:])],\n",
    "           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(sar)\n",
    "df[df[13]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
