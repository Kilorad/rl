{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#превращает файлы с последовательностями картинок в файлы с последовательностями их эмбеддингов\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../env')\n",
    "sys.path.insert(1, '../agents')\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import resnet_v2, mobilenet_v2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMAGE_NET_TARGET_SIZE = (224, 224)\n",
    "\n",
    "class Img2Vec(object):\n",
    "    #benchmark:\n",
    "    #resnet50 5.68 s/100 times\n",
    "    #resnet_v2.ResNet101V2 Wall time: 9.56 s\n",
    "    #resnet_v2.ResNet152V2 Wall time: 10.9 s\n",
    "    #mobilenet_v2.MobileNetV2 Wall time: 3.9 s\n",
    "    def __init__(self):\n",
    "        \n",
    "        #model = resnet_v2.ResNet101V2(weights='imagenet')\n",
    "        model = mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "        #layer_name = 'avg_pool'\n",
    "        layer_name = model.layers[-2].name\n",
    "        self.intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "\n",
    "    def get_vec_file(self, image_path):\n",
    "        \"\"\" Gets a vector embedding from an image.\n",
    "        :param image_path: path to image on filesystem\n",
    "        :returns: numpy ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        img = image.load_img(image_path, target_size=_IMAGE_NET_TARGET_SIZE)\n",
    "        \n",
    "        return self.get_vec_raw(x)\n",
    "    def get_vec_raw(self, x):\n",
    "        if len(np.shape(x))==3:\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "        else:\n",
    "            x = np.expand_dims(x, axis=1)\n",
    "        x = mobilenet_v2.preprocess_input(x)\n",
    "        if np.shape(x)[0]>1:\n",
    "            #перевести в dataset\n",
    "            x = tf.data.Dataset.from_tensor_slices(x)\n",
    "            #list_dataset = list(x.as_numpy_iterator())\n",
    "            #print(len(list_dataset), np.shape(list_dataset[0]))\n",
    "        intermediate_output = self.intermediate_layer_model.predict(x,batch_size=100)\n",
    "        #i2v.intermediate_layer_model.predict()#help is here\n",
    "        return intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "list_imgs = pickle.load(open('../movies_save_raw/seaquest_sarsa_113440696.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = list_imgs[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2v = Img2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2 batches). You may need to use the repeat() function when building your dataset.\n",
      "[0.5531439  0.         0.3613987  ... 0.         0.38746122 0.09749935]\n",
      "1280\n",
      "(1280,)\n"
     ]
    }
   ],
   "source": [
    "embedding = i2v.get_vec_raw(img)\n",
    "print(embedding)\n",
    "print(len(embedding))\n",
    "print(np.shape(embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.85 s, sys: 655 ms, total: 6.5 s\n",
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#бенчмарк\n",
    "for i in range(100):\n",
    "    embedding = i2v.get_vec_raw(img)\n",
    "#embedding = i2v.get_vec_file('./Krasivaya-koshka.jpg')\n",
    "#embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16 2020-08-06 23:07:16.019754\n",
      "1 16 2020-08-06 23:07:34.491828\n",
      "2 16 2020-08-06 23:07:45.391772\n",
      "3 16 2020-08-06 23:08:02.791982\n",
      "4 16 2020-08-06 23:08:20.667358\n",
      "5 16 2020-08-06 23:08:38.107572\n",
      "5 16 2020-08-06 23:08:38.107917\n",
      "6 16 2020-08-06 23:08:56.109979\n",
      "7 16 2020-08-06 23:09:15.124264\n",
      "8 16 2020-08-06 23:09:33.356594\n",
      "9 16 2020-08-06 23:09:51.093189\n",
      "10 16 2020-08-06 23:10:09.653273\n",
      "11 16 2020-08-06 23:10:27.734897\n",
      "11 16 2020-08-06 23:10:27.735227\n",
      "12 16 2020-08-06 23:10:45.727182\n",
      "13 16 2020-08-06 23:11:03.451523\n"
     ]
    }
   ],
   "source": [
    "#список названий файлов\n",
    "directory = '../movies_save_raw/'\n",
    "files = os.listdir(directory)\n",
    "i2v = Img2Vec()\n",
    "i = 0\n",
    "for file in files:\n",
    "    print(i, len(files), pd.Timestamp.now())\n",
    "    if (not ('README') in file) and not ('.ipynb_checkpoints' in file):\n",
    "        list_imgs = pickle.load(open('../movies_save_raw/' + file,'rb'))\n",
    "        list_imgs = np.array(list_imgs)\n",
    "        list_imgs = list_imgs[:,:,:,:]\n",
    "        embedding_package = i2v.get_vec_raw(list_imgs)\n",
    "        #а теперь эти эмбеддинги выгрузить в другой файл\n",
    "        #размерность (1001, 1280)\n",
    "        with open('./movies_save_embeddings/' + file, 'wb') as f:\n",
    "            pickle.dump(embedding_package, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
