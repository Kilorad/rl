{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './env')\n",
    "sys.path.insert(1, './agents')\n",
    "\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import aa_gun\n",
    "import strategy_imitation, sarsa, model_based,clusterized_ql\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "EPISODES = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit\n",
      "episode: 0   score: 1.75   memory length: 250   epsilon: 0.22212431388282694\n",
      "hit\n",
      "episode: 1   score: 2.1875   memory length: 500   epsilon: 0.04933921081791662\n",
      "episode: 2   score: 1.0   memory length: 750   epsilon: 0.010959438350449888\n",
      "hit\n",
      "episode: 3   score: 1.5   memory length: 1000   epsilon: 0.009953376870880467\n",
      "hit\n",
      "hit\n",
      "episode: 4   score: 3.625   memory length: 1250   epsilon: 0.009953376870880467\n",
      "episode: 5   score: 2.25   memory length: 1500   epsilon: 0.009953376870880467\n",
      "hit\n",
      "episode: 6   score: 1.875   memory length: 1750   epsilon: 0.009953376870880467\n",
      "episode: 7   score: 1.25   memory length: 2000   epsilon: 0.009953376870880467\n",
      "hit\n",
      "episode: 8   score: 1.4375   memory length: 2250   epsilon: 0.009953376870880467\n",
      "episode: 9   score: 1.0   memory length: 2500   epsilon: 0.009953376870880467\n",
      "hit\n",
      "episode: 10   score: 2.5625   memory length: 2750   epsilon: 0.009953376870880467\n",
      "hit\n",
      "quality (1.2252210597031203, 0.9999999999999998)\n",
      "episode: 11   score: 1.3125   memory length: 3000   epsilon: 0.009953376870880467\n",
      "quality (1.2295018601311578, 1.0000000000000002)\n",
      "episode: 12   score: 0   memory length: 3250   epsilon: 0.009953376870880467\n",
      "quality (1.2262509732858502, 1.0000000000000002)\n",
      "episode: 13   score: 0   memory length: 3500   epsilon: 0.009953376870880467\n",
      "quality (1.2395609663536453, 0.9999999999999998)\n",
      "episode: 14   score: 0   memory length: 3750   epsilon: 0.009953376870880467\n",
      "quality (1.218570893884916, 1.0000000000000002)\n",
      "episode: 15   score: 0.125   memory length: 4000   epsilon: 0.009953376870880467\n",
      "quality (1.2670483742444412, 0.9999999999999998)\n",
      "episode: 16   score: 0   memory length: 4250   epsilon: 0.009953376870880467\n",
      "quality (1.2439438639225846, 1.0)\n",
      "episode: 17   score: 0   memory length: 4500   epsilon: 0.009953376870880467\n",
      "quality (1.238482219161411, 0.9999999999999998)\n",
      "episode: 18   score: 0.0625   memory length: 4750   epsilon: 0.009953376870880467\n",
      "quality (1.2355419962365173, 1.0)\n",
      "episode: 19   score: 0   memory length: 5000   epsilon: 0.009953376870880467\n",
      "quality (1.2435420241475368, 0.9999999999999997)\n",
      "episode: 20   score: 0   memory length: 5250   epsilon: 0.009953376870880467\n",
      "quality (1.2368045298871586, 1.0)\n",
      "episode: 21   score: 0   memory length: 5500   epsilon: 0.009953376870880467\n",
      "quality (1.243379153925004, 1.0000000000000004)\n",
      "episode: 22   score: 0   memory length: 5750   epsilon: 0.009953376870880467\n",
      "quality (1.2389974115318698, 0.9999999999999998)\n",
      "episode: 23   score: 0   memory length: 6000   epsilon: 0.009953376870880467\n",
      "quality (1.2320391438693827, 0.9999999999999998)\n",
      "episode: 24   score: 0   memory length: 6250   epsilon: 0.009953376870880467\n",
      "quality (1.2393845464915643, 1.0000000000000002)\n",
      "episode: 25   score: 0   memory length: 6500   epsilon: 0.009953376870880467\n",
      "quality (1.2468620962728159, 1.0)\n",
      "episode: 26   score: 0   memory length: 6750   epsilon: 0.009953376870880467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-96159ea0e127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# every episode update the target model to be same with model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# every episode, plot the play time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/QL_test/rl/agents/clusterized_ql.py\u001b[0m in \u001b[0;36mupdate_target_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_target_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/QL_test/rl/agents/clusterized_ql.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, stop, verbose)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_clusterizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0msans_mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsr_mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclusterizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaq_mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_q_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msans_mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsr_mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanning_horison\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/QL_test/rl/agents/clusterized_ql.py\u001b[0m in \u001b[0;36mselect_clusterizer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mn_clusters\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.07\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mclusterizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_clusterizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0msans_mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsr_mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mquality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msans_mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnsr_mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mquality_max\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/QL_test/rl/agents/clusterized_ql.py\u001b[0m in \u001b[0;36mmake_matrix\u001b[0;34m(self, clusterizer)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusterizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mznamen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_clusters\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_arr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mznamen\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_clusters\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mns_clusters\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_arr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mznamen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 1930\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   1931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f660e0ac8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In case of CartPole-v1, maximum length of episode is 500\n",
    "env = aa_gun.AA_gun_simple0_env()\n",
    "#env = gym.make('AirRaid-ram-v0')\n",
    "#env = gym.make('Robotank-ramNoFrameskip-v0')\n",
    "#env = gym.make('Seaquest-ramNoFrameskip-v0')\n",
    "#env=CartPoleEnv9()\n",
    "# get size of state and action from environment\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "#agent = DoubleDQNAgent(state_size, action_size)\n",
    "#agent = model_based.ModelBasedAgent(state_size, action_size)\n",
    "agent = clusterized_ql.ClusterQLAgent(state_size, action_size)\n",
    "agent.train_start=3000\n",
    "#agent = strategy_imitation.ImitAgent(state_size, action_size)\n",
    "agent.render=True\n",
    "\n",
    "scores, episodes = [], []\n",
    "reward_lst = []\n",
    "s_list=[]\n",
    "a_list=[]\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    while not done:\n",
    "        if (e in range(100,300)) or (e in range(300,306)) or (e in range(400,406)) or (e in range(500,506)) or (e in range(600,604)):\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "\n",
    "        # get action for the current state and go one step in environment\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        # if an action make the episode end, then gives penalty of -100\n",
    "        \n",
    "\n",
    "        # save the sample <s, a, r, s'> to the replay memory\n",
    "        reward_curr=reward\n",
    "        #if done:\n",
    "        #    reward_curr -= 100\n",
    "        agent.append_sample(state, action, reward_curr, next_state, done)\n",
    "        #if next_state[0,11]!=reward:\n",
    "        #    print('state[13]!=reward',state[0,11],reward)\n",
    "        #\n",
    "        s_list.append(state)\n",
    "        a_list.append(action)\n",
    "        reward_lst.append(reward)\n",
    "        #\n",
    "        \n",
    "        # every time step do the training\n",
    "        agent.train_model()\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            # every episode update the target model to be same with model\n",
    "            agent.update_target_model()\n",
    "\n",
    "            # every episode, plot the play time\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, scores, 'b')\n",
    "            #pylab.savefig(\"./save_graph/aa_gun_dqn.png\")\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.s), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 490\n",
    "            # stop training\n",
    "\n",
    "    # save the model\n",
    "    #if e % 50 == 0:\n",
    "    #    agent.model.save_weights(\"./save_model/aa_gun_dqn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.sans_mn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.saq_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.nsr_mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sar_table(s,a,r):\n",
    "    #print(np.array(a,ndmin=2).T.shape)\n",
    "    #print(np.array(r,ndmin=2).T.shape)\n",
    "    #print(np.array(s,ndmin=2)[:,0,:].shape)\n",
    "    return np.hstack( (np.array(s,ndmin=2)[:,0,:],np.array(a,ndmin=2).T,np.array(r,ndmin=2).T) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(np.mean(reward_lst))\n",
    "plt.plot(reward_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(agent.r_disco)\n",
    "#plt.plot(agent.d*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(reward_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтобы анализировать разрешимость задачи\n",
    "def replicate_reward(sar,border=0,wanted_part=0.5):\n",
    "    part = np.mean(sar[:,-1:]>border)\n",
    "    if part==0:\n",
    "        print('ERROR')\n",
    "        return(sar)\n",
    "    else:\n",
    "        while part<wanted_part:\n",
    "            sar=np.vstack((sar,sar[np.where(sar[:,-1:]>border)[0],:]))\n",
    "            part = np.mean(sar[:,-1:]>border)\n",
    "        print(part)\n",
    "        return(sar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sar=make_sar_table(s_list,a_list,reward_lst)\n",
    "sar=replicate_reward(sar)\n",
    "X=sar[1:,:]\n",
    "Y=sar[:-1,:]\n",
    "Y=sar[:-1,-1:]\n",
    "Y=sar[1:,-1:]\n",
    "sar_width=X.shape[1]\n",
    "nn = Sequential()\n",
    "nn.add(Dense(200, input_dim=sar_width, activation='relu',\n",
    "                kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(200, activation='relu',\n",
    "                kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(BatchNormalization())\n",
    "nn.add(Dense(200, activation='relu',\n",
    "                kernel_initializer='he_uniform',kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(BatchNormalization())\n",
    "#nn.add(Dense(sar_width, activation='linear',\n",
    "#                kernel_initializer='he_uniform'))\n",
    "nn.add(Dense(1, activation='linear',\n",
    "                kernel_initializer='he_uniform'))\n",
    "\n",
    "nn.summary()\n",
    "nn.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "l=X.shape[0]\n",
    "X_train=X[:int(l/2),:]\n",
    "Y_train=Y[:int(l/2),:]\n",
    "X_test=X[int(l/2):,:]\n",
    "Y_test=Y[int(l/2):,:]\n",
    "nn.fit(X_train, Y_train, batch_size=1200,epochs=30000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=np.array(nn.predict(X_test),ndmin=2)\n",
    "mse = np.mean((Y_pred-Y_test)**2)\n",
    "print(mse)\n",
    "rmae=np.mean(np.abs(Y_pred-Y_test))/np.mean(np.abs(Y_test))\n",
    "print(rmae)\n",
    "rmae_diversed=np.mean(np.abs(Y_pred-Y_test),axis=0)/np.mean(np.abs(Y_test),axis=0)\n",
    "print(rmae_diversed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnumn_num=-1\n",
    "plt.plot(Y_pred[:3000,colnumn_num])\n",
    "plt.plot(Y_test[:3000,colnumn_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train (переобучение?)\n",
    "Y_pred=np.array(nn.predict(X_train),ndmin=2)\n",
    "mse = np.mean((Y_pred-Y_train)**2)\n",
    "print(mse)\n",
    "rmae=np.mean(np.abs(Y_pred-Y_train))/np.mean(np.abs(Y_train))\n",
    "print(rmae)\n",
    "rmae_diversed=np.mean(np.abs(Y_pred-Y_train),axis=0)/np.mean(np.abs(Y_train),axis=0)\n",
    "print(rmae_diversed)\n",
    "\n",
    "colnumn_num=-1\n",
    "plt.plot(Y_pred[:1300,colnumn_num])\n",
    "plt.plot(Y_train[:1300,colnumn_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgbparams = {\n",
    "    'booster':'gbtree',\n",
    "    'metric':'mse',\n",
    "    'objective':'reg:squarederror',\n",
    "    'verbosity':0,\n",
    "    'max_depth': 7,\n",
    "    'n_estimators': 90,\n",
    "    'eta': 0.3,\n",
    "    'nthreads': 2,\n",
    "    'seed':0\n",
    "}\n",
    "nn=xgb.XGBRegressor(**xgbparams)\n",
    "nn.fit(X_train[:int(l/4),:], Y_train[:int(l/4),:],\n",
    "           eval_set=[(X_train[int(l/4):,:], Y_train[int(l/4):,:])],\n",
    "           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(sar)\n",
    "df[df[13]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
